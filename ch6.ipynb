{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CH6 EXERCISE 1"
      ],
      "metadata": {
        "id": "gS_VbwKKg8PN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part A"
      ],
      "metadata": {
        "id": "UZEKRtSviZli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "random.seed(1628)\n",
        "\n",
        "def generate_random_dataset(num_instances, num_dimensions):\n",
        "  X = np.random.rand(num_instances, num_dimensions)\n",
        "  y = np.random.randint(0, 2, size=num_instances)\n",
        "  return X, y\n",
        "\n",
        "def compute_capacity(X, y, num_instances):\n",
        "  num_removed = 0\n",
        "  knn = KNeighborsClassifier(n_neighbors=1)\n",
        "  for i in range(num_instances):\n",
        "    X_copy = np.delete(X, i, axis=0)\n",
        "    y_copy = np.delete(y, i)\n",
        "\n",
        "    knn.fit(X_copy, y_copy)\n",
        "    y_pred = knn.predict([X[i]])\n",
        "\n",
        "    if (y_pred[0]==y[i]):\n",
        "      num_removed += 1\n",
        "\n",
        "  return (num_instances - num_removed)\n",
        "\n",
        "def sample_multiple_times(d, n_full):\n",
        "  iterations = 100\n",
        "  total = 0\n",
        "  for iter in range(iterations):\n",
        "    X_train, y_train = generate_random_dataset(n_full, d)\n",
        "    total += compute_capacity(X_train, y_train, n_full)\n",
        "  n_avg = total / iterations\n",
        "  result = n_full/n_avg\n",
        "  print(\"d={}: n_full={}, Avg. req. points for memorization n_avg={:.2f}, n_full/n_avg={:.16f}\".format(d, n_full, n_avg, result))\n",
        "\n",
        "\n",
        "sample_multiple_times(2, 4)\n",
        "sample_multiple_times(4, 16)\n",
        "sample_multiple_times(8, 256)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nuJZaxA1sNf",
        "outputId": "9e08059b-ffd9-46d6-e839-8a41709ac893"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d=2: n_full=4, Avg. req. points for memorization n_avg=2.17, n_full/n_avg=1.8433179723502304\n",
            "d=4: n_full=16, Avg. req. points for memorization n_avg=8.39, n_full/n_avg=1.9070321811680571\n",
            "d=8: n_full=256, Avg. req. points for memorization n_avg=128.76, n_full/n_avg=1.9881950916433677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d=2: n_full=4, Avg. req. points for memorization n_avg=2.17, n_full/n_avg=1.8433179723502304\n",
        "\n",
        "d=4: n_full=16, Avg. req. points for memorization n_avg=8.39, n_full/n_avg=1.9070321811680571\n",
        "\n",
        "d=8: n_full=256, Avg. req. points for memorization n_avg=128.76, n_full/n_avg=1.9881950916433677"
      ],
      "metadata": {
        "id": "k-8O00aelqeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since n_full/n_avg is ~ 2 and approaches 2 as d increases, information limit of 2 bits per parameter holds for KNN."
      ],
      "metadata": {
        "id": "hQYfANi6mIoe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part B"
      ],
      "metadata": {
        "id": "HdAs0M-3icMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For multiclass\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "random.seed(1628)\n",
        "\n",
        "def generate_random_dataset(num_instances, num_dimensions, num_classes):\n",
        "  X = np.random.rand(num_instances, num_dimensions)\n",
        "  y = np.random.randint(num_classes, size=num_instances)\n",
        "  return X, y\n",
        "\n",
        "def compute_capacity(X, y, num_instances):\n",
        "  num_removed = 0\n",
        "  knn = KNeighborsClassifier(n_neighbors=1)\n",
        "  for i in range(num_instances):\n",
        "    X_copy = np.delete(X, i, axis=0)\n",
        "    y_copy = np.delete(y, i)\n",
        "\n",
        "    knn.fit(X_copy, y_copy)\n",
        "    y_pred = knn.predict([X[i]])\n",
        "\n",
        "    if (y_pred[0]==y[i]):\n",
        "      num_removed += 1\n",
        "  return (num_instances - num_removed)\n",
        "\n",
        "def sample_multiple_times(d, n_full, num_classes):\n",
        "  iterations = 100\n",
        "  total = 0\n",
        "  for iter in range(iterations):\n",
        "    X_train, y_train = generate_random_dataset(n_full, d, num_classes)\n",
        "    total += compute_capacity(X_train, y_train, n_full)\n",
        "  n_avg = total / iterations\n",
        "  result = n_full/n_avg\n",
        "  print(\"d={}: n_full={}, Avg. req. points for memorization n_avg={:.2f}, n_full/n_avg={:.16f}\".format(d, n_full, n_avg, result, num_classes))\n",
        "\n",
        "sample_multiple_times(2, 4, 8)\n",
        "sample_multiple_times(4, 16, 8)\n",
        "sample_multiple_times(8, 256, 8)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFI307PkgWpZ",
        "outputId": "16b0ddcb-8a45-4e45-d854-5a379d9be685"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "d=2: n_full=4, Avg. req. points for memorization n_avg=3.63, n_full/n_avg=1.1019283746556474\n",
            "d=4: n_full=16, Avg. req. points for memorization n_avg=14.12, n_full/n_avg=1.1331444759206799\n",
            "d=8: n_full=256, Avg. req. points for memorization n_avg=223.58, n_full/n_avg=1.1450040254047769\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "d=2: n_full=4, Avg. req. points for memorization n_avg=3.63, n_full/n_avg=1.1019283746556474\n",
        "\n",
        "d=4: n_full=16, Avg. req. points for memorization n_avg=14.12, n_full/n_avg=1.1331444759206799\n",
        "\n",
        "d=8: n_full=256, Avg. req. points for memorization n_avg=223.58, n_full/n_avg=1.1450040254047769"
      ],
      "metadata": {
        "id": "cLD_Lyx0hcuc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected n_full/n_avg is c/c-1 (compression). With 8 classes, you would expect it to approach 1.14 as d increases, which you can see happens here."
      ],
      "metadata": {
        "id": "OJRkUGp2iMoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CH6 EXERCISE 2"
      ],
      "metadata": {
        "id": "8gy669DbfTfm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Part A"
      ],
      "metadata": {
        "id": "ni8UUWj3iJNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.tree import _tree\n",
        "from sklearn.tree import export_text\n",
        "from scipy.stats import randint\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# Borrowed function to print decisions in a clean, human-friendly way, credit: https://mljar.com/blog/extract-rules-decision-tree/\n",
        "def get_rules(tree, feature_names, class_names):\n",
        "    tree_ = tree.tree_\n",
        "    feature_name = [\n",
        "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
        "        for i in tree_.feature\n",
        "    ]\n",
        "\n",
        "    paths = []\n",
        "    path = []\n",
        "\n",
        "    def recurse(node, path, paths):\n",
        "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
        "            name = feature_name[node]\n",
        "            threshold = tree_.threshold[node]\n",
        "            p1, p2 = list(path), list(path)\n",
        "            p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
        "            recurse(tree_.children_left[node], p1, paths)\n",
        "            p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
        "            recurse(tree_.children_right[node], p2, paths)\n",
        "        else:\n",
        "            path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
        "            paths += [path]\n",
        "\n",
        "    recurse(0, path, paths)\n",
        "\n",
        "    # sort by samples count\n",
        "    samples_count = [p[-1][1] for p in paths]\n",
        "    ii = list(np.argsort(samples_count))\n",
        "    paths = [paths[i] for i in reversed(ii)]\n",
        "\n",
        "    rules = []\n",
        "    for path in paths:\n",
        "        rule = \"if \"\n",
        "\n",
        "        for p in path[:-1]:\n",
        "            if rule != \"if \":\n",
        "                rule += \" and \"\n",
        "            rule += str(p)\n",
        "        rule += \" then \"\n",
        "        if class_names is None:\n",
        "            rule += \"response: \"+str(np.round(path[-1][0][0][0],3))\n",
        "        else:\n",
        "            classes = path[-1][0][0]\n",
        "            l = np.argmax(classes)\n",
        "            rule += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n",
        "        rule += f\" | based on {path[-1][1]:,} samples\"\n",
        "        rules += [rule]\n",
        "\n",
        "    return rules"
      ],
      "metadata": {
        "id": "O_51frKebwp1"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize decision tree classifier and grid search for tuning\n",
        "\n",
        "# Load and split dataset\n",
        "\n",
        "data = load_breast_cancer()\n",
        "breast_cancer_X = data.data\n",
        "breast_cancer_y = data.target\n",
        "\n",
        "def count_rules(X, y, depth, nodes, print_flag):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  classifier = DecisionTreeClassifier(max_depth = depth, max_leaf_nodes = nodes)\n",
        "  model = classifier.fit(X_train, y_train)\n",
        "\n",
        "  # predict on the test data\n",
        "  y_pred = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  if(print_flag == True):\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Max tree depth:\", model.get_depth())\n",
        "    print(\"Num leaf nodes:\", model.tree_.n_leaves)\n",
        "\n",
        "  # Print out rules (follow tree branch until \"class\" -> 1 if/else statement)\n",
        "  text_representation = tree.export_text(classifier)\n",
        "  #print(text_representation)\n",
        "  num_clauses_final = text_representation.count(\"<=\") + text_representation.count(\">\")\n",
        "  #print(str(num_clauses_final) + \" if/else clauses\")\n",
        "\n",
        "  # Print out rules (and count of how many), formatted to be readable\n",
        "  rules = get_rules(classifier, data.feature_names, data.target_names)\n",
        "  #for r in rules:\n",
        "  #    print(r)\n",
        "  #print(str(len(rules)) + \" decisions\")\n",
        "  if(print_flag == True):\n",
        "    print(\"\\nIf/then clauses: \" + str(num_clauses_final) + \"\\nDecisions: \" + str(len(rules)))\n",
        "  return num_clauses_final, accuracy, len(rules)\n"
      ],
      "metadata": {
        "id": "1DeB4lvufi5f"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original\n",
        "num_clauses, accuracy, decisions = count_rules(breast_cancer_X, breast_cancer_y, None, None, True)\n",
        "breast_cancer_original_accuracy = accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWuS5HuTVuNc",
        "outputId": "127bd5f6-fea4-4fa5-9094-4bfafbc261f0"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9385964912280702\n",
            "Max tree depth: 7\n",
            "Num leaf nodes: 16\n",
            "\n",
            "If/then clauses: 30\n",
            "Decisions: 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning depth\n",
        "current_min_clauses = 30\n",
        "current_min_decisions = 16\n",
        "for i in range(1,8):\n",
        "  num_clauses, accuracy, decisions = count_rules(breast_cancer_X, breast_cancer_y, i, 16, False)\n",
        "  if (accuracy >= breast_cancer_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"depth: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"depth: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a9EDX6hHowc",
        "outputId": "4cc40e60-c3bb-435e-feeb-61ab01604709"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9385964912280702\n",
            "clauses: 14\n",
            "depth: 3\n",
            "\n",
            "\n",
            "accuracy: 0.9385964912280702\n",
            "decisions: 8\n",
            "depth: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning nodes\n",
        "current_min_clauses = 30\n",
        "current_min_decisions = 16\n",
        "for i in range(2,17):\n",
        "  num_clauses, accuracy, decisions = count_rules(breast_cancer_X, breast_cancer_y, 7, i, False)\n",
        "  if (accuracy >= breast_cancer_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"nodes: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"nodes: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REbTALtiKMBB",
        "outputId": "fd302d7b-80cb-4ede-d038-90985168eab7"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.9473684210526315\n",
            "clauses: 8\n",
            "nodes: 5\n",
            "\n",
            "\n",
            "accuracy: 0.9473684210526315\n",
            "decisions: 5\n",
            "nodes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune both (FINAL RESULT)\n",
        "num_clauses, accuracy, decisions = count_rules(breast_cancer_X, breast_cancer_y, 3, 5, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE2a9EeOZAJ_",
        "outputId": "e4c74c26-7db6-414d-9414-73d97a724424"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9473684210526315\n",
            "Max tree depth: 3\n",
            "Num leaf nodes: 5\n",
            "\n",
            "If/then clauses: 8\n",
            "Decisions: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum clauses (ignoring accuracy)\n",
        "num_clauses, accuracy, decisions = count_rules(breast_cancer_X, breast_cancer_y, 1, 2, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn7BegxsJbmF",
        "outputId": "cac7d289-81e8-4f57-92cb-6c408fa705b5"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8947368421052632\n",
            "Max tree depth: 1\n",
            "Num leaf nodes: 2\n",
            "\n",
            "If/then clauses: 2\n",
            "Decisions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part B"
      ],
      "metadata": {
        "id": "r9vxVE3-iQ_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another binary classification dataset: australian credit\n",
        "\n"
      ],
      "metadata": {
        "id": "-y5NfApkLFBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "id": "50BlUKvlLbDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "australian_data = fetch_openml(name='Australian')\n",
        "australian_X = australian_data.data\n",
        "australian_y = australian_data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05aTRczLLMSQ",
        "outputId": "28429176-9e31-4349-d043-03564b83aa27"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_clauses, accuracy, decisions = count_rules(australian_X, australian_y, None, None, True)\n",
        "australian_original_accuracy = accuracy\n",
        "australian_original_decisions = decisions\n",
        "australian_original_clauses = num_clauses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR1kIcopLl1i",
        "outputId": "7d65b2af-0093-4cc3-f305-b1c052a91025"
      },
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8478260869565217\n",
            "Max tree depth: 12\n",
            "Num leaf nodes: 70\n",
            "\n",
            "If/then clauses: 134\n",
            "Decisions: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning depth\n",
        "current_min_clauses = australian_original_clauses\n",
        "current_min_decisions = australian_original_decisions\n",
        "for i in range(1,13):\n",
        "  num_clauses, accuracy, decisions = count_rules(australian_X, australian_y, i, 70, False)\n",
        "  if (accuracy >= australian_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"depth: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"depth: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqZgZD8AO78d",
        "outputId": "1a668f72-9bc1-4117-b157-3c0b2d39d93e"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8478260869565217\n",
            "clauses: 14\n",
            "depth: 3\n",
            "\n",
            "\n",
            "accuracy: 0.8478260869565217\n",
            "decisions: 8\n",
            "depth: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning nodes\n",
        "current_min_clauses = australian_original_clauses\n",
        "current_min_decisions = australian_original_decisions\n",
        "for i in range(2,71):\n",
        "  num_clauses, accuracy, decisions = count_rules(australian_X, australian_y, 12, i, False)\n",
        "  if (accuracy >= australian_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"nodes: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"nodes: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfkLlpLMPK-i",
        "outputId": "c063bc5c-f1e0-48b7-94be-d0d384695c47"
      },
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.8623188405797102\n",
            "clauses: 8\n",
            "nodes: 5\n",
            "\n",
            "\n",
            "accuracy: 0.8623188405797102\n",
            "decisions: 5\n",
            "nodes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Best result (FINAL RESULT)\n",
        "# Note: not using both best depth and best nodes\n",
        "num_clauses, accuracy, decisions = count_rules(australian_X, australian_y, None, 5, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvZwA1JnPYSv",
        "outputId": "02536149-6640-4014-8e43-ccc755d9834b"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8623188405797102\n",
            "Max tree depth: 4\n",
            "Num leaf nodes: 5\n",
            "\n",
            "If/then clauses: 8\n",
            "Decisions: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum clauses (ignoring accuracy)\n",
        "num_clauses, accuracy, decisions = count_rules(australian_X, australian_y, 1, 2, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8T1fykPciA",
        "outputId": "0f5e2ff3-d450-4bd0-8811-3e9ef92fbaec"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8405797101449275\n",
            "Max tree depth: 1\n",
            "Num leaf nodes: 2\n",
            "\n",
            "If/then clauses: 2\n",
            "Decisions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another binary classification dataset: ilpd liver dataset"
      ],
      "metadata": {
        "id": "Wzw_YB93Ever"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "liver_data = fetch_openml(name='ilpd-numeric')\n",
        "liver_X = liver_data.data\n",
        "liver_y = liver_data.target"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8HnuciVEzZb",
        "outputId": "4f6717e3-601b-46eb-f604-a6a22d24dfe7"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:301: UserWarning: Multiple active versions of the dataset matching the name ilpd-numeric exist. Versions may be fundamentally different, returning version 1.\n",
            "  warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_clauses, accuracy, decisions = count_rules(liver_X, liver_y, None, None, True)\n",
        "liver_original_accuracy = accuracy\n",
        "liver_original_decisions = decisions\n",
        "liver_original_clauses = num_clauses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jC_Sk6cUGLST",
        "outputId": "37427d6c-c3cb-442d-a969-361f11dcc0b1"
      },
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7008547008547008\n",
            "Max tree depth: 18\n",
            "Num leaf nodes: 102\n",
            "\n",
            "If/then clauses: 158\n",
            "Decisions: 102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning depth\n",
        "current_min_clauses = liver_original_clauses\n",
        "current_min_decisions = liver_original_decisions\n",
        "for i in range(1,19):\n",
        "  num_clauses, accuracy, decisions = count_rules(liver_X, liver_y, i, 102, False)\n",
        "  if (accuracy >= liver_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"depth: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"depth: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VmuByXgKN0n",
        "outputId": "743d4514-3814-40a4-81ee-69a0eca5021e"
      },
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7435897435897436\n",
            "clauses: 2\n",
            "depth: 1\n",
            "\n",
            "\n",
            "accuracy: 0.7435897435897436\n",
            "decisions: 2\n",
            "depth: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning nodes\n",
        "current_min_clauses = liver_original_clauses\n",
        "current_min_decisions = liver_original_decisions\n",
        "for i in range(2,103):\n",
        "  num_clauses, accuracy, decisions = count_rules(liver_X, liver_y, 18, i, False)\n",
        "  if (accuracy >= liver_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"nodes: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"nodes: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YcQRokIKjqz",
        "outputId": "6819b006-dcec-4605-8b57-1ae85b84fb90"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7435897435897436\n",
            "clauses: 2\n",
            "nodes: 2\n",
            "\n",
            "\n",
            "accuracy: 0.7435897435897436\n",
            "decisions: 2\n",
            "nodes: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune both (FINAL RESULT and minimum possible clauses)\n",
        "num_clauses, accuracy, decisions = count_rules(liver_X, liver_y, 1, 2, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5zsq0XuK6V_",
        "outputId": "b64eaf1e-3093-4de1-f9a9-9f4896be700d"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7435897435897436\n",
            "Max tree depth: 1\n",
            "Num leaf nodes: 2\n",
            "\n",
            "If/then clauses: 2\n",
            "Decisions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part C"
      ],
      "metadata": {
        "id": "Ds0bYFLGiT8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6c: Random dataset\n",
        "rand_X = np.random.rand(500, 2)\n",
        "rand_y = np.random.randint(0, 2, size=500)"
      ],
      "metadata": {
        "id": "RT2X6TwbE_0p"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original\n",
        "num_clauses, accuracy, decisions = count_rules(rand_X, rand_y, None, None, True)\n",
        "rand_original_accuracy = accuracy\n",
        "rand_original_decisions = decisions\n",
        "rand_original_clauses = num_clauses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyfCYY7PGpkV",
        "outputId": "411e5d24-7cbe-40d2-e040-635140066444"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.51\n",
            "Max tree depth: 20\n",
            "Num leaf nodes: 144\n",
            "\n",
            "If/then clauses: 206\n",
            "Decisions: 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning depth\n",
        "current_min_clauses = rand_original_clauses\n",
        "current_min_decisions = rand_original_decisions\n",
        "for i in range(1,21):\n",
        "  num_clauses, accuracy, decisions = count_rules(rand_X, rand_y, i, 144, False)\n",
        "  if (accuracy >= rand_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"depth: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"depth: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VhZUbG7Jw4T",
        "outputId": "de4398d3-b44b-4c59-fd6a-b7ebfcf37c45"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.52\n",
            "clauses: 58\n",
            "depth: 6\n",
            "\n",
            "\n",
            "accuracy: 0.52\n",
            "decisions: 30\n",
            "depth: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning nodes\n",
        "current_min_clauses = rand_original_clauses\n",
        "current_min_decisions = rand_original_decisions\n",
        "for i in range(2,145):\n",
        "  num_clauses, accuracy, decisions = count_rules(rand_X, rand_y, 20, i, False)\n",
        "  if (accuracy >= rand_original_accuracy):\n",
        "    if (num_clauses < current_min_clauses):\n",
        "      current_min_clauses = num_clauses\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"clauses: \" + str(num_clauses))\n",
        "      print(\"nodes: \" + str(i))\n",
        "      print('\\n')\n",
        "    if (decisions < current_min_decisions):\n",
        "      current_min_decisions = decisions\n",
        "      print(\"accuracy: \"  + str(accuracy))\n",
        "      print(\"decisions: \" + str(decisions))\n",
        "      print(\"nodes: \" + str(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99i5t9TEXA3d",
        "outputId": "dd961307-1ee6-40f9-f8bd-ee2b477c8382"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.51\n",
            "clauses: 154\n",
            "nodes: 97\n",
            "\n",
            "\n",
            "accuracy: 0.51\n",
            "decisions: 97\n",
            "nodes: 97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tune both (FINAL RESULT)\n",
        "num_clauses, accuracy, decisions = count_rules(rand_X, rand_y, 6, 97, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyKzrFwjKwP8",
        "outputId": "5d4e8e7b-9860-4fc5-bf32-e98e5296c982"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.51\n",
            "Max tree depth: 6\n",
            "Num leaf nodes: 30\n",
            "\n",
            "If/then clauses: 58\n",
            "Decisions: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Minimum clauses (ignoring accuracy)\n",
        "num_clauses, accuracy, decisions = count_rules(rand_X, rand_y, 1, 2, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BN4PdkLlImc0",
        "outputId": "aff37060-b230-446e-f0f0-def8d473d6e3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "Max tree depth: 1\n",
            "Num leaf nodes: 2\n",
            "\n",
            "If/then clauses: 2\n",
            "Decisions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our current simulation on random data, we are training on random train dataset and testing on random test dataset (two different sets of data). In this case, you could need an infinite number of if/else statements.\n",
        "\n",
        "If we were to instead test and train on the same dataset, we would need up to the *number of instances* of if/else statements to be able to achieve 100% accuracy (one if/else statement per instance)."
      ],
      "metadata": {
        "id": "AQUWNUvhgo97"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CH6 EXERCISE 3"
      ],
      "metadata": {
        "id": "LGR_FhJYoYnA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part A"
      ],
      "metadata": {
        "id": "4XayuzxGihxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import string\n",
        "import lzma\n",
        "\n",
        "# Generate a long random string\n",
        "random_string = ''.join(random.choices(string.ascii_letters + string.digits, k=1000000))\n",
        "unique_letters = set(random_string)\n",
        "c = len(unique_letters)\n",
        "print(\"c =\", c)\n",
        "\n",
        "# Compress the string using LZMA\n",
        "compressed_string = lzma.compress(random_string.encode())\n",
        "\n",
        "# Calculate compression ratio\n",
        "compression_ratio = len(random_string) / len(compressed_string)\n",
        "\n",
        "print(f\"Original string length: {len(random_string)} bytes\")\n",
        "print(f\"Compressed string length: {len(compressed_string)} bytes\")\n",
        "print(f\"Compression ratio: {compression_ratio:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4ZQtXi-NQY2",
        "outputId": "9c411378-e3d8-44ff-b3b3-90f86b07e5cc"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c = 62\n",
            "Original string length: 1000000 bytes\n",
            "Compressed string length: 760732 bytes\n",
            "Compression ratio: 1.31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part B"
      ],
      "metadata": {
        "id": "nTOtP4oCijsa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The expected compression ratio should be between 1 and 1.0164 (=62/61, bound derived from c/c-1 from the book)."
      ],
      "metadata": {
        "id": "5OfYUuzHGU0e"
      }
    }
  ]
}