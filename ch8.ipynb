{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CH8 EXERCISE 1"
      ],
      "metadata": {
        "id": "F7o_vzzYuXUw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "a. MEC = 3\\*4 + min(3\\*4,3) + min(4,3) = 12 + 3 + 3 = 18\n",
        "\n",
        "b. MEC = 3 + 4 + 4 = 11\n",
        "\n",
        "c. For a, 18 rows.\n",
        "For b, 11 rows.\n",
        "Because it is binary classification, we have 1 bit per row. MEC of 18 bits / 1 bit per row = 18 rows. MEC of 11 bits / 1 bit per row = 11 rows.\n",
        "\n",
        "d. For a, 18/2 = 9 rows. For b, 11/2 = 5.5 -> 5 rows\n",
        "This is similar to part c except we now have 2 bits per row. MEC of 18 bits / 2 bits per row = 9 rows. MEC of 11 bits / 2 bits per row = 5.5 -> 5 rows."
      ],
      "metadata": {
        "id": "xv991T-YuZ1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CH8 EXERCISE 2"
      ],
      "metadata": {
        "id": "L42TxC6UzU3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "See drawings in writeup PDF\n"
      ],
      "metadata": {
        "id": "dyIKaN-6i9uO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CH8 EXERCISE 4"
      ],
      "metadata": {
        "id": "l-nx3M0RzyFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part A"
      ],
      "metadata": {
        "id": "H6GuJBymirXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Brain capacity = neurons * 2 * inputs = $10^{11}$ * 2 * 1000 = 2 * $10^{14}$\n",
        "\n",
        "\\\\\n",
        "\n",
        "\"The human body sends 11 million bits per second to the brain for processing, yet the conscious mind seems to be able to process only 50 bits per second.\"\n",
        "\n",
        "seconds in a year * 22 year of age = 693,880,000 seconds\n",
        "\n",
        "Total experienced sensory experiences in bits = 11 million * 693880000 = 7.633 * $10^{15}$ bits (EXCEEDS BRAIN CAPACITY)\n",
        "Total processed sensory experience in bits = 50 * 693880000 = 34,694,000,000 bits\n",
        "\n",
        "\\\\\n",
        "\n",
        "\"Some studies suggest that humans forget approximately 50% of new information within an hour of learning it. Within 24 hours, that number goes up to an average of 70%!\" -> Memorize 30% of the information we process.\n",
        "\n",
        "Total memorized information in bits = 0.3 * 34,694,000,000 bits = 10,408,200,000 bits\n",
        "\n",
        "\\\\\n",
        "\n",
        "number of words in Shakespeare's works = 884,647 words\n",
        "estimate of number of bits per word = log2(884647) = 19.755 -> 20 bits\n",
        "Shakespeare's works in bits = 20 * 884,647 = 17,692,940 bits\n",
        "\n",
        "\\\\\n",
        "\n",
        "Total information = 34,694,000,000 + 10,408,200,000 + 17,692,940 = 45,119,892,940 bits\n",
        "\n",
        "\\\\\n",
        "\n",
        "For all of the individual information contents we calculated, they are less than our brain capacity (which makes sense). All combined together, it is still less than our brain capacity, so our brain is not full. However, if we looked at how much sensory experience we EXPERIENCED (but not perceived), which is about 7 * $10^{15}$ bits of information, then we have exceeded our brain capacity.\n",
        "\n",
        "\\\\\n",
        "\n",
        "Sources:\n",
        "* https://www.britannica.com/science/information-theory/Physiology\n",
        "* https://www.folger.edu/explore/shakespeares-works/frequently-asked-questions/#:~:text=How%20many%20words%20did%20Shakespeare,884%2C647%20words%20and%20118%2C406%20lines.\n",
        "* https://www.crossrivertherapy.com/memory-capacity-of-human-brain#:~:text=A%20Human%20Brain%3F-,The%20memory%20capacity%20of%20the%20brain%20is%20around%202.5%20million,an%20average%20of%2070%25!\n"
      ],
      "metadata": {
        "id": "e4FZK4NfjzVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part B"
      ],
      "metadata": {
        "id": "17mB6Z2qi0c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Algo 8\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def memorize(data, labels):\n",
        "    thresholds = 0\n",
        "\n",
        "    table = []\n",
        "\n",
        "    for dat, lab in zip(data, labels):\n",
        "        data_sum = sum(dat)\n",
        "        table.append([data_sum, lab])\n",
        "\n",
        "    sorted_table = sorted(table, key=lambda x: x[0])\n",
        "    class_label = 0\n",
        "\n",
        "    for row in range(len(data)):\n",
        "        if sorted_table[row][1] != class_label:\n",
        "            class_label = sorted_table[row][1]\n",
        "            thresholds += 1\n",
        "\n",
        "    min_thresholds = np.log2(thresholds + 1)\n",
        "    # mec = (int)(min_thresholds * (len(data[0]) + 1) + (min_thresholds + 1)) # original from book, corrected to be an error\n",
        "    mec = (int)(min_thresholds * (len(data[0]) + 1) + (min_thresholds))\n",
        "    return mec"
      ],
      "metadata": {
        "id": "YMaKveJ0kEpf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Algo 8 to work with more than one binary classification (NOT multi-class)\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def memorize_multi_binary(data, labels):\n",
        "\n",
        "    total_mec = 0\n",
        "\n",
        "    for labels in labels_list:\n",
        "      thresholds = []\n",
        "      table = []\n",
        "\n",
        "      for dat, lab in zip(data, labels):\n",
        "          data_sum = sum(dat)\n",
        "          table.append([data_sum, lab])\n",
        "\n",
        "\n",
        "      sorted_table = sorted(table, key=lambda x: x[0])\n",
        "      class_label = 0\n",
        "\n",
        "      for row in range(len(data)):\n",
        "          if sorted_table[row][1] != class_label:\n",
        "              class_label = sorted_table[row][1]\n",
        "              thresholds.append(1)\n",
        "\n",
        "      num_thresholds = len(thresholds)\n",
        "      min_thresholds = np.log2(num_thresholds + 1)\n",
        "      mec =(int)(min_thresholds * (len(data[0]) + 1) + (min_thresholds))\n",
        "      total_mec += mec\n",
        "    return mec\n"
      ],
      "metadata": {
        "id": "h9xI77p-1VXl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Algo 8 to work with multi-class\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def memorize(data, labels, num_classes):\n",
        "\n",
        "    thresholds = 0\n",
        "    table = []\n",
        "\n",
        "    for dat, lab in zip(data, labels):\n",
        "        data_sum = sum(dat)\n",
        "        table.append([data_sum, lab])\n",
        "\n",
        "    sorted_table = sorted(table, key=lambda x: x[0])\n",
        "    class_label = 0\n",
        "\n",
        "    for row in range(len(data)):\n",
        "        if sorted_table[row][1] != class_label:\n",
        "            class_label = sorted_table[row][1]\n",
        "            thresholds += 1\n",
        "\n",
        "    min_thresholds = np.log2(thresholds + 1)\n",
        "    # mec = (int)(min_thresholds * (len(data[0]) + 1) + (min_thresholds + 1)) # original from book, corrected to be an error\n",
        "\n",
        "    # CHANGE: consider more than one node in final layer\n",
        "    mec = (int)(min_thresholds * (len(data[0]) + 1) + min((min_thresholds+1)*num_classes, min_thresholds))\n",
        "    return mec"
      ],
      "metadata": {
        "id": "A0wPrEZAQrsO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Part C"
      ],
      "metadata": {
        "id": "lZ5RQA6-i4O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Algo 8 to work with regression\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# note that xi are not the inputs of the table but outputs of the layer output layer depends on\n",
        "def memorize(data, labels, epsilon):\n",
        "    thresholds = 0\n",
        "    table = []\n",
        "    discrete_labels = []\n",
        "\n",
        "    # define discrete labels for continuous output space\n",
        "    current_value = min(labels)\n",
        "    while current_value < max(labels):\n",
        "        discrete_labels.append(current_value)\n",
        "        current_value += epsilon\n",
        "\n",
        "    for row in range(len(data)):\n",
        "      table.append((np.sum(data[row]), labels[row]))\n",
        "\n",
        "    sorted_table = sorted(table, key=lambda x: x[0])\n",
        "    print(sorted_table)\n",
        "\n",
        "    # if predicted output is in the interval, label same\n",
        "    # if predicted output not in interval, increment threshold and move to next interval\n",
        "    class_label = 0\n",
        "    for row in range(len(data)):\n",
        "        #print(sorted_table[row])\n",
        "        if (class_label == None) or (abs(sorted_table[row][1] - discrete_labels[class_label]) > epsilon):\n",
        "          # moving to correct next interval\n",
        "          while(abs(sorted_table[row][1] - discrete_labels[class_label]) > epsilon):\n",
        "            class_label +=1\n",
        "          thresholds += 1\n",
        "          #print(class_label)\n",
        "\n",
        "    min_thresholds = np.log2(thresholds + 1)\n",
        "    mec = (int)(min_thresholds * (len(data[0]) + 1) + (min_thresholds))\n",
        "    #print(mec)\n",
        "    return mec"
      ],
      "metadata": {
        "id": "hKM9JuoVTK-P"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}